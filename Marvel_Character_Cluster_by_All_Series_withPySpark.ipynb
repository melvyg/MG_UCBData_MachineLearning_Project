{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "from marvel_keys import apikey, privateKey, marvel_char_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join('marvel_data.csv')\n",
    "\n",
    "marvel_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Spider-Man \n",
       "1    Captain America \n",
       "2          Wolverine \n",
       "3           Iron Man \n",
       "4               Thor \n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marvel_df['name'][:2800].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_test = ['Iron Man', 'Captain America', 'Thor', 'Black Widow', 'Hulk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Request and Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import urllib.parse\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gateway.marvel.com:443/v1/public/characters'\n",
    "\n",
    "ts = str(round(time.time()))\n",
    "\n",
    "hsh = hashlib.md5(bytes(ts+privateKey+apikey, 'utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'RequestThrottled', 'message': 'You have exceeded your rate limit.  Please try again later.'}\n",
      "{'code': 'RequestThrottled', 'message': 'You have exceeded your rate limit.  Please try again later.'}\n",
      "{'code': 'RequestThrottled', 'message': 'You have exceeded your rate limit.  Please try again later.'}\n",
      "{'code': 'RequestThrottled', 'message': 'You have exceeded your rate limit.  Please try again later.'}\n",
      "{'code': 'RequestThrottled', 'message': 'You have exceeded your rate limit.  Please try again later.'}\n"
     ]
    }
   ],
   "source": [
    "url = 'https://gateway.marvel.com:443/v1/public/characters'\n",
    "\n",
    "#Initialize python dict containing data\n",
    "\n",
    "marvel_data = []\n",
    "\n",
    "for hero in marvel_char_list:\n",
    "    \n",
    "    search_data = {'id':[],\n",
    "                'name':[],\n",
    "               'description':[],\n",
    "                'comics_avail':[],\n",
    "                'comics_list':[],\n",
    "                'series_avail':[],\n",
    "                'series_list':[],\n",
    "                'events_avail':[],\n",
    "                'events_list':[]}\n",
    "    \n",
    "    #Set parameters for search\n",
    "    params = {'ts': ts,\n",
    "            'apikey': apikey,\n",
    "              'hash': hsh,\n",
    "             'name': hero,\n",
    "             'limit': '100'}\n",
    "    \n",
    "    #Set up response request\n",
    "    response = req.get(url, params=params).json()\n",
    "    print(response)\n",
    "    \n",
    "    try:\n",
    "        #Extract data initial data\n",
    "        hero_data = response['data']['results'][0]\n",
    "        search_data['id'].append(hero_data['id'])\n",
    "        search_data['name'].append(hero_data['name'])\n",
    "        search_data['description'].append(hero_data['description'])\n",
    "        search_data['comics_avail'].append(hero_data['comics']['available'])\n",
    "        search_data['series_avail'].append(hero_data['series']['available'])\n",
    "        search_data['events_avail'].append(hero_data['events']['available'])\n",
    "\n",
    "        #Set length of comics, series, and events to iterate over\n",
    "        comics_length = len(hero_data['comics']['items'])\n",
    "        series_length = len(hero_data['series']['items'])\n",
    "        events_length = len(hero_data['events']['items'])\n",
    "\n",
    "        #Iterate through items of comics, series and events to obtain names\n",
    "        for n in range(comics_length):\n",
    "            comics_list = hero_data['comics']['items'][n]\n",
    "            search_data['comics_list'].append(comics_list['name'])\n",
    "\n",
    "        for n in range(series_length):\n",
    "            series_list = hero_data['series']['items'][n]\n",
    "            search_data['series_list'].append(series_list['name'])\n",
    "\n",
    "        for n in range(events_length):\n",
    "            events_list = hero_data['events']['items'][n]\n",
    "            search_data['events_list'].append(events_list['name'])\n",
    "            \n",
    "        marvel_data.append(search_data.copy())\n",
    "        \n",
    "    except IndexError:\n",
    "        print(f'Having Error with {hero}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(marvel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_df = pd.DataFrame.from_dict(marvel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Brackets\n",
    "\n",
    "marvel_df['comics_avail'] = marvel_df['comics_avail'].str.get(0)\n",
    "# marvel_df['comics_list'] = marvel_df['comics_list'].str.get(0)\n",
    "marvel_df['description'] = marvel_df['description'].str.get(0)\n",
    "marvel_df['events_avail'] = marvel_df['events_avail'].str.get(0)\n",
    "marvel_df['id'] = marvel_df['id'].str.get(0)\n",
    "marvel_df['name'] = marvel_df['name'].str.get(0)\n",
    "marvel_df['series_avail'] = marvel_df['series_avail'].str.get(0)\n",
    "# marvel_df['series_list'] = marvel_df['series_list'].str.get(0)\n",
    "# marvel_df['events_list'] = marvel_df['events_list'].str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_clean_df = marvel_df.loc[marvel_df['series_avail'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(marvel_clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove brackets and quotations\n",
    "marvel_clean_df['series_list'] = marvel_clean_df['series_list'].map(lambda x: str(x))\n",
    "marvel_clean_df['series_list'] = marvel_clean_df['series_list'].map(lambda x: x.strip('[]'))\n",
    "# marvel_clean_df['series_list'] = marvel_clean_df['series_list'].map(lambda x: x.strip(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove brackets and quotations\n",
    "marvel_clean_df['comics_list'] = marvel_clean_df['comics_list'].map(lambda x: str(x))\n",
    "marvel_clean_df['comics_list'] = marvel_clean_df['comics_list'].map(lambda x: x.strip('[]'))\n",
    "# marvel_clean_df['comics_list'] = marvel_clean_df['comics_list'].map(lambda x: x.strip(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove brackets and quotations\n",
    "marvel_clean_df['events_list'] = marvel_clean_df['events_list'].map(lambda x: str(x))\n",
    "marvel_clean_df['events_list'] = marvel_clean_df['events_list'].map(lambda x: x.strip('[]'))\n",
    "# marvel_clean_df['events_list'] = marvel_clean_df['events_list'].map(lambda x: x.strip(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_clean_df['Combined'] = marvel_clean_df[['comics_list', 'events_list', 'series_list']].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
    "                                                                                                                           \n",
    "                                                                                                                           \n",
    "                                                                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_clean_df['Combined'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapted from brandonrose.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Using PySpark and Adapation from brandonrose.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark app and session\n",
    "spark = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_spark = spark.createDataFrame(marvel_clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Combined\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.transform(marvel_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate remover\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframe\n",
    "tokenized_filt = remover.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_filt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = tokenized_filt.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = tokenized_df.loc[tokenized_df['comics_avail'] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create necessary lists for kmeans\n",
    "\n",
    "names_list = []\n",
    "all_filtered = []\n",
    "all_comics = []\n",
    "all_series = []\n",
    "all_events = []\n",
    "stemmed_words = []\n",
    "comics_avail_list = []\n",
    "events_avail_list = []\n",
    "series_avail_list = []\n",
    "everything_list = []\n",
    "\n",
    "for n in range(len(tokenized_df)):\n",
    "    names_list.append(tokenized_df.iloc[n]['name'])\n",
    "    all_filtered.extend(tokenized_df.iloc[n]['filtered'])\n",
    "    all_comics.append(tokenized_df.iloc[n]['comics_list'])\n",
    "    all_series.append(tokenized_df.iloc[n]['series_list'])\n",
    "    all_events.append(tokenized_df.iloc[n]['events_list'])\n",
    "    stemmed_words.extend(tokenized_df.iloc[n]['words'])\n",
    "    comics_avail_list.append(tokenized_df.iloc[n]['comics_avail'])\n",
    "    events_avail_list.append(tokenized_df.iloc[n]['events_avail'])\n",
    "    series_avail_list.append(tokenized_df.iloc[n]['series_avail'])\n",
    "    everything_list.append(tokenized_df.iloc[n]['Combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(everything_list)==len(names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorized_list = all_series\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(vectorized_list) #fit the vectorizer to descriptions\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "print\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 6\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#uncomment the below to save your model \n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = {'heroes': names_list, 'comics_available': comics_avail_list,\n",
    "          'events_available': events_avail_list, 'series_available': series_avail_list,\n",
    "          'comics+series+events': everything_list, 'cluster': clusters,}\n",
    "\n",
    "frame = pd.DataFrame(heroes, index = [clusters] , columns = ['heroes', \n",
    "                                                             'comics_available', 'events_available',\n",
    "                                                             'series_available','cluster', 'comics+series+events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame['cluster'].value_counts() #number of films per cluster (clusters from 0 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # for os.path.basename\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "MDS()\n",
    "\n",
    "# convert two components as we're plotting points in a two-dimensional plane\n",
    "# \"precomputed\" because we provide a distance matrix\n",
    "# we will also specify `random_state` so the plot is reproducible.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "xs, ys = pos[:, 0], pos[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(pos)\n",
    "predicted_clusters = kmeans.predict(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Get current size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    " \n",
    "# Prints: [8.0, 6.0]\n",
    "print(\"Current size:\", fig_size)\n",
    " \n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 5\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.scatter(pos[:, 0], pos[:, 1], \n",
    "            c=predicted_clusters, s=100, \n",
    "            cmap='Paired')\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='#A4CFE0',\n",
    "                          label='Avengers/Fantastic Four', markersize=15),\n",
    "                  Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='#9EC6DF',\n",
    "                          label='Avengers Villians', markersize=15),\n",
    "                  Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='#FFBE6E',\n",
    "                          label='Guardians of the Galaxy', markersize=15),\n",
    "                  Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='#A94D24',\n",
    "                          label='Fantastic Four', markersize=15),\n",
    "                  Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='#B2DF8A',\n",
    "                          label='X-Men', markersize=15),\n",
    "                  Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='#B2DF8A',\n",
    "                          label='Runaways', markersize=15),\n",
    "                  Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='#FFFCB6',\n",
    "                          label='Hulk', markersize=15)]\n",
    "\n",
    "# plt.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.3, 1.014))\n",
    "\n",
    "# plt.savefig('marvel_cluster_byEverything_7.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Cluster Chart demonstrated by brandonrose.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up colors per clusters using a dict\n",
    "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#FCB230', 4:'#30BBFC', 5:'#3058FC', 6:'#FC30F3',\n",
    "                 7: '#9BE3E5'}\n",
    "\n",
    "#set up cluster names using a dict\n",
    "cluster_names = {0: 'Guardians of the Galaxy', \n",
    "                 1: 'Fantastic Four/Avengers', \n",
    "                 2: 'Spider-Man',\n",
    "                3: 'Four',\n",
    "                4: 'X-Men',\n",
    "                5: 'Other',\n",
    "                6: 'Test',\n",
    "                7: 'Test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some ipython magic to show the matplotlib plots inline\n",
    "%matplotlib inline \n",
    "\n",
    "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=names_list)) \n",
    "\n",
    "#group by cluster\n",
    "groups = df.groupby('label')\n",
    "\n",
    "\n",
    "# set up plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8)) # set size\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=14, \n",
    "            label=cluster_names[name], color=cluster_colors[name], \n",
    "            mec='none')\n",
    "#     ax.set_aspect('auto')\n",
    "#     ax.tick_params(\\\n",
    "#         axis= 'x',          \n",
    "#         which='both',      \n",
    "#         bottom='off',     \n",
    "#         top='off',        \n",
    "#         labelbottom='off')\n",
    "#     ax.tick_params(\\\n",
    "#         axis= 'y',         \n",
    "#         which='both',     \n",
    "#         left='off',      \n",
    "#         top='off',        \n",
    "#         labelleft='off')\n",
    "    \n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.01))  #show legend with only 1 point\n",
    "    \n",
    "plt.show() #show the plot\n",
    "\n",
    "#uncomment the below to save the plot if need be\n",
    "#plt.savefig('clusters_small_noaxes.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define custom toolbar location\n",
    "class TopToolbar(mpld3.plugins.PluginBase):\n",
    "    \"\"\"Plugin for moving toolbar to top of figure\"\"\"\n",
    "\n",
    "    JAVASCRIPT = \"\"\"\n",
    "    mpld3.register_plugin(\"toptoolbar\", TopToolbar);\n",
    "    TopToolbar.prototype = Object.create(mpld3.Plugin.prototype);\n",
    "    TopToolbar.prototype.constructor = TopToolbar;\n",
    "    function TopToolbar(fig, props){\n",
    "        mpld3.Plugin.call(this, fig, props);\n",
    "    };\n",
    "\n",
    "    TopToolbar.prototype.draw = function(){\n",
    "      // the toolbar svg doesn't exist\n",
    "      // yet, so first draw it\n",
    "      this.fig.toolbar.draw();\n",
    "\n",
    "      // then change the y position to be\n",
    "      // at the top of the figure\n",
    "      this.fig.toolbar.toolbar.attr(\"x\", 150);\n",
    "      this.fig.toolbar.toolbar.attr(\"y\", 400);\n",
    "\n",
    "      // then remove the draw function,\n",
    "      // so that it is not called again\n",
    "      this.fig.toolbar.draw = function() {}\n",
    "    }\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.dict_ = {\"type\": \"toptoolbar\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame that has the result of the MDS plus the cluster numbers and heroes\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, heroes=names_list)) \n",
    "\n",
    "#group by cluster\n",
    "groups = df.groupby('label')\n",
    "\n",
    "#define custom css to format the font and to remove the axis labeling\n",
    "css = \"\"\"\n",
    "text.mpld3-text, div.mpld3-tooltip {\n",
    "  font-family:Arial, Helvetica, sans-serif;\n",
    "}\n",
    "\n",
    "g.mpld3-xaxis, g.mpld3-yaxis {\n",
    "display: none; }\n",
    "\n",
    "svg.mpld3-figure {\n",
    "margin-left: -200px;}\n",
    "\"\"\"\n",
    "\n",
    "# Plot \n",
    "fig, ax = plt.subplots(figsize=(14,6)) #set plot size\n",
    "ax.margins(0.03) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "for name, group in groups:\n",
    "    points = ax.plot(group.x, group.y, marker='o', linestyle='', ms=18, \n",
    "                     label=cluster_names[name], mec='none', \n",
    "                     color=cluster_colors[name])\n",
    "    ax.set_aspect('auto')\n",
    "    labels = [i for i in group.heroes]\n",
    "    \n",
    "    #set tooltip using points, labels and the already defined 'css'\n",
    "    tooltip = mpld3.plugins.PointHTMLTooltip(points[0], labels,\n",
    "                                       voffset=10, hoffset=10, css=css)\n",
    "    #connect tooltip to fig\n",
    "    mpld3.plugins.connect(fig, tooltip, TopToolbar())    \n",
    "    \n",
    "    #set tick marks as blank\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    ax.axes.get_yaxis().set_ticks([])\n",
    "    \n",
    "    #set axis as blank\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "ax.legend(numpoints=1) #show legend with only one dot\n",
    "\n",
    "mpld3.display() #show the plot\n",
    "\n",
    "#uncomment the below to export to html\n",
    "#html = mpld3.fig_to_html(fig)\n",
    "#print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'] = list(frame.comics_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_outliers = df.loc[df['label'] != 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_outliers.to_csv('marvel_cluster_no_OL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df['label'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
